{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55df7a0c-6ecb-4840-9a62-29c7908d7135",
   "metadata": {},
   "source": [
    "### Single Perceptron Neural Networks for Linear Regression\n",
    "\n",
    "You are ready to building your first neural network with a single perceptron.\n",
    "\n",
    "After this assignment you will be able to:\n",
    "\n",
    "Implement a neural network with a single perceptron and one input node for simple linear regression\n",
    "Implement forward propagation using matrix multiplication\n",
    "Implement a neural network with a single perceptron and two input nodes for multiple linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd21f3f-3160-45e4-b8d1-9298d94f60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "\n",
    "# Set a seed so that the results are consistent.\n",
    "np.random.seed(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30806217-13c0-4694-a3b8-9f41ae179835",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18770c4e-755c-4176-83f4-04c6c6cb23c4",
   "metadata": {},
   "source": [
    "First, let's get the dataset you will work on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301900b6-6869-4951-bc59-1ff9a00b175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset X:\n",
      "[[ 0.3190391  -1.07296862  0.86540763 -0.17242821  1.14472371  0.50249434\n",
      "  -2.3015387  -0.68372786 -0.38405435 -0.87785842 -2.06014071 -1.10061918\n",
      "  -1.09989127  1.13376944  1.74481176 -0.12289023 -0.93576943  1.62434536\n",
      "   1.46210794  0.90159072 -0.7612069   0.53035547 -0.52817175 -0.26788808\n",
      "   0.58281521  0.04221375  0.90085595 -0.24937038 -0.61175641 -0.3224172 ]]\n",
      "Training dataset Y\n",
      "[[ -3.01854669 -65.65047675  26.96755728   8.70562603  57.94332628\n",
      "   -0.69293498 -78.66594473 -12.73881492 -13.26721663 -24.80488085\n",
      "  -74.24484385 -39.99533724 -22.70174437  73.46766345  55.7257405\n",
      "   23.80417646 -13.45481508  25.57952246  75.91238321  50.91155323\n",
      "  -43.7191551   -1.7025559  -16.44931235 -33.54041234  20.4505961\n",
      "   18.35949302  37.69029586  -1.04801683  -4.47915933 -20.89431647]]\n"
     ]
    }
   ],
   "source": [
    "m = 30\n",
    "\n",
    "X, Y = make_regression(n_samples=m, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = X.reshape((1, m))\n",
    "Y = Y.reshape((1, m))\n",
    "\n",
    "print('Training dataset X:')\n",
    "print(X)\n",
    "print('Training dataset Y')\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d72bba7-f9eb-4c12-8adc-2f3e145863eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,  Y, c=\"black\")\n",
    "\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e809c-fde9-4b00-a5f9-3fae744dee84",
   "metadata": {},
   "source": [
    "## Exercice 1 \n",
    "\n",
    "What is the shape of the variables X and Y? In addition, how many training examples do you have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c453ba4-9409-4131-b593-b281a89e9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761681a8-138e-4114-9de9-86274fcb850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_y = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "587d75e8-e699-4cd8-809b-ed9e731c1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (1, 30)\n",
      "The shape of Y: (1, 30)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X: ' + str(shape_x))\n",
    "print ('The shape of Y: ' + str(shape_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ffbed-72ae-4ece-8f8c-80f9227a5d1b",
   "metadata": {},
   "source": [
    "We have 30 training examples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5bb8d-1616-4fe7-a1cd-41c2b8f8ff72",
   "metadata": {},
   "source": [
    "##  Implementation of the Neural Network Model for Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ab8b4-0140-4d5f-b3fb-e0c04f9179f9",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Define two variables:\n",
    "\n",
    "- n_x: the size of the input layer\n",
    "- n_y: the size of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb4fd1f6-0466-40e4-a275-fe4c01c32a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = shape_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84eff723-caaf-4980-9a2b-42c85f39f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = shape_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729239f9-ecfd-4952-b002-b0ae32b904e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x (size of the input layer): 1\n",
      "n_y (size of the output layer): 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"n_x (size of the input layer): {n_x}\")\n",
    "print(f\"n_y (size of the output layer): {n_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11be22-f9dc-47db-b25c-230b2d3ee7f2",
   "metadata": {},
   "source": [
    "###  Initialize the Model's Parameters\n",
    "\n",
    "Implement the function initialize_parameters().\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Make sure your parameters' sizes are right. Refer to the neural network figure above if needed.\n",
    "- You will initialize the weights matrix with random values.\n",
    "    - Use: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b).\n",
    "- You will initialize the bias vector as zeros.\n",
    "    - Use: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d34edc96-e138-443a-b43f-1277fc6ed8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_y):\n",
    "     W = np.random.randn(n_y, n_x) * 0.01\n",
    "     b = np.zeros((n_y, 1))\n",
    "     parameters = {\n",
    "        \"W\": W,\n",
    "        \"b\": b\n",
    "     }\n",
    "     return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4a0c64d-5640-4c70-9a39-870d485bd9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.01788628]]\n",
      "b = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(n_x, n_y)\n",
    "print(\"W = \" + str(parameters[\"W\"]))\n",
    "print(\"b = \" + str(parameters[\"b\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61287bbf-b553-49cf-8c8c-4e67c9384ff4",
   "metadata": {},
   "source": [
    "### The Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99901261-205f-451f-a816-97f737df78b7",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "Implement forward_propagation()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e314ef7-d9ae-4393-adaa-5562b82ff857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W = parameters.get(\"W\")\n",
    "    b = parameters.get(\"b\")\n",
    "    Z = np.matmul(W,X) + b\n",
    "    Y_hat = Z\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd84eeb3-c7ae-4a0c-849f-56caaf137de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00570642 -0.01919142  0.01547893 -0.0030841   0.02047485  0.00898776\n",
      "  -0.04116598 -0.01222935 -0.00686931 -0.01570163 -0.03684826 -0.01968599\n",
      "  -0.01967297  0.02027892  0.0312082  -0.00219805 -0.01673744  0.0290535\n",
      "   0.02615168  0.01612611 -0.01361516  0.00948609 -0.00944703 -0.00479152\n",
      "   0.0104244   0.00075505  0.01611297 -0.00446031 -0.01094205 -0.00576685]]\n"
     ]
    }
   ],
   "source": [
    "Y_hat = forward_propagation(X, parameters)\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aca259-2324-4f6d-8582-31bd894bbfb0",
   "metadata": {},
   "source": [
    "Remember that your weights were just initialized with some random values, so the model has not been trained yet.\n",
    "Define a cost function  which will be used to train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8495ba7-20fd-44b6-8dc6-aaf2d72b99bd",
   "metadata": {},
   "source": [
    "The compute_cost function calculates the error between the neural network's predictions (Y_hat) and the true values (Y) using mean squared error. It sums the squared differences, then divides by the number of examples to get the average cost, which helps adjust the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1203e47-0738-4b50-bb4b-7a3472c756a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y_hat,Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = np.sum((Y_hat - Y)**2)/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c03e46e0-c804-40be-9806-11d87dd086c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 790.2189412622606\n"
     ]
    }
   ],
   "source": [
    "print(\"cost = \" + str(compute_cost(Y_hat, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d93f2-0a0e-495c-b60b-9da47f657e60",
   "metadata": {},
   "source": [
    "You want to minimize the cost value, bringing it as close as possible to 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14132775-8ef5-4cb3-891b-e0593df12314",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = w3_tools.train_nn(parameters, Y_hat, X, Y)\n",
    "\n",
    "print(\"W = \" + str(parameters[\"W\"]))\n",
    "print(\"b = \" + str(parameters[\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e14d45e3-76d3-46ae-bfa3-ed4e0b0d5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [[43.63366703]]\n",
    "b = [[0.17926448]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d7cb6-54ae-473a-9331-762397b8e6df",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Build your neural network model in nn_model().\n",
    "\n",
    "Instructions: The neural network model has to use the previous functions in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f1260f5-7fe2-4cd6-8614-47472d1705e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, num_iterations=10, print_cost=False):\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (~ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### START CODE HERE ### (~ 2 lines of code)\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"Y_hat\".\n",
    "        Y_hat = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"Y_hat, Y\". Outputs: \"cost\".\n",
    "        cost = compute_cost(Y_hat, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        \n",
    "        # Parameters update.\n",
    "        parameters = w3_tools.train_nn(parameters, Y_hat, X, Y) \n",
    "        \n",
    "        # Print the cost every iteration.\n",
    "        if print_cost:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8768cd5-2944-492c-b535-e73e0d957dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = nn_model(X, Y, num_iterations=15, print_cost=True)\n",
    "print(\"W = \" + str(parameters[\"W\"]))\n",
    "print(\"b = \" + str(parameters[\"b\"]))\n",
    "\n",
    "W_simple = parameters[\"W\"]\n",
    "b_simple = parameters[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5261c-d462-44d0-872a-909ec0516045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost after iteration 0: 791.431703\n",
    "Cost after iteration 1: 176.530000\n",
    "Cost after iteration 2: 143.772255\n",
    "Cost after iteration 3: 141.433606\n",
    "Cost after iteration 4: 141.248744\n",
    "Cost after iteration 5: 141.233728\n",
    "Cost after iteration 6: 141.232500\n",
    "Cost after iteration 7: 141.232400\n",
    "Cost after iteration 8: 141.232391\n",
    "Cost after iteration 9: 141.232391\n",
    "Cost after iteration 10: 141.232391\n",
    "Cost after iteration 11: 141.232391\n",
    "Cost after iteration 12: 141.232391\n",
    "Cost after iteration 13: 141.232391\n",
    "Cost after iteration 14: 141.232391\n",
    "W = [[35.71958208]]\n",
    "b = [[2.2893077]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0fc74-2a45-41e5-9ce0-474da28b39f2",
   "metadata": {},
   "source": [
    "You can see that after a few iterations the cost function does not change anymore (the model converges).\n",
    "\n",
    "Note: This is a very simple model. In reality the models do not converge that quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728616a2-6d0d-4a2c-8ccd-f3f7bada4b48",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "Models are not always as simple as the one above. In some cases your output is dependent on more than just one variable. Let's look at the case where the output depends on two input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43cd0754-3193-4650-be7e-1cd2d106fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Projet/Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a761146-1276-4250-b4f6-96a3cc4423a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf7062-cd85-4ad2-b732-c8301747f9a7",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab521748-23a2-4a69-b6f2-7afd2e190a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df[['GrLivArea', 'OverallQual']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ce033-7266-4cf5-bf59-ef258d034637",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49fe716d-6b75-4d65-b657-b8ec0737889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_multi = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38d59f39-4d92-40df-9797-b52ac0d63fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_multi:\n",
      "      GrLivArea  OverallQual\n",
      "0          1710            7\n",
      "1          1262            6\n",
      "2          1786            7\n",
      "3          1717            7\n",
      "4          2198            8\n",
      "...         ...          ...\n",
      "1455       1647            6\n",
      "1456       2073            6\n",
      "1457       2340            7\n",
      "1458       1078            5\n",
      "1459       1256            5\n",
      "\n",
      "[1460 rows x 2 columns]\n",
      "\n",
      "Y_multi:\n",
      "0       208500\n",
      "1       181500\n",
      "2       223500\n",
      "3       140000\n",
      "4       250000\n",
      "         ...  \n",
      "1455    175000\n",
      "1456    210000\n",
      "1457    266500\n",
      "1458    142125\n",
      "1459    147500\n",
      "Name: SalePrice, Length: 1460, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_multi:\\n{X_multi}\\n\")\n",
    "print(f\"Y_multi:\\n{Y_multi}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5239f-8b0d-40a8-af7b-daf2bdd82b4d",
   "metadata": {},
   "source": [
    "All the original arrays have different units. To train the neural network efficiently, we use normalization: subtract the array's mean from each element and divide by its standard deviation. This brings the data to the same scale for better performance. Mean and standard deviation will be covered in detail in the third Course of the Specialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4fe6df5-2aa8-4bb4-912a-1ffc5ca8e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3643: FutureWarning: The behavior of DataFrame.std with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_multi_norm = (X_multi - np.mean(X_multi))/np.std(X_multi)\n",
    "Y_multi_norm = (Y_multi - np.mean(Y_multi))/np.std(Y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27ca9688-9151-42b1-bf4b-cc5efc38cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (2, 1460)\n",
      "The shape of Y: (1, 1460)\n",
      "I have m = 1460 training examples!\n"
     ]
    }
   ],
   "source": [
    "X_multi_norm = np.array(X_multi_norm).T\n",
    "Y_multi_norm = np.array(Y_multi_norm).reshape((1, len(Y_multi_norm)))\n",
    "\n",
    "print ('The shape of X: ' + str(X_multi_norm.shape))\n",
    "print ('The shape of Y: ' + str(Y_multi_norm.shape))\n",
    "print ('I have m = %d training examples!' % (X_multi_norm.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480656a4-e669-4bf1-8c82-c1ee0344a204",
   "metadata": {},
   "source": [
    "### Performance of the Neural Network Model for Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9eaf79-770b-4a31-9c73-2bd5bb0618dc",
   "metadata": {},
   "source": [
    "The magic is that now you do not need to change anything in your neural network implementation! Go through the code in section 2 and see that if you pass new datasets X_multi_norm and Y_multi_norm, the input layer size \n",
    " will get equal to \n",
    " and the rest of the implementation will remain exactly the same. That's the power of the neural networks (and matrix multiplication)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8da6c3-70b7-4ee4-8bf3-c5a18cd541ab",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "Run the constructed above neural network model nn_model() for 100 iterations, passing the training dataset saved in the arrays X_multi_norm and Y_multi_norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b48a5-7af2-4766-b0c3-4867cb742cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~ 1 line of code)\n",
    "parameters_multi = nn_model(X_multi_norm, Y_multi_norm, num_iterations=100, print_cost=True)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"W = \" + str(parameters_multi[\"W\"]))\n",
    "print(\"b = \" + str(parameters_multi[\"b\"]))\n",
    "\n",
    "W_multi = parameters_multi[\"W\"]\n",
    "b_multi = parameters_multi[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac0f10-5158-4426-87ca-8a18d2aac2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost after iteration 0: 0.489797\n",
    "Cost after iteration 1: 0.429192\n",
    "Cost after iteration 2: 0.380299\n",
    "Cost after iteration 3: 0.340051\n",
    "Cost after iteration 4: 0.306705\n",
    "Cost after iteration 5: 0.279020\n",
    "Cost after iteration 6: 0.256020\n",
    "Cost after iteration 7: 0.236908\n",
    "Cost after iteration 8: 0.221025\n",
    "Cost after iteration 9: 0.207827\n",
    "Cost after iteration 10: 0.196858\n",
    "Cost after iteration 11: 0.187743\n",
    "Cost after iteration 12: 0.180169\n",
    "Cost after iteration 13: 0.173874\n",
    "Cost after iteration 14: 0.168642\n",
    "Cost after iteration 15: 0.164295\n",
    "Cost after iteration 16: 0.160682\n",
    "Cost after iteration 17: 0.157680\n",
    "Cost after iteration 18: 0.155185\n",
    "Cost after iteration 19: 0.153111\n",
    "Cost after iteration 20: 0.151388\n",
    "Cost after iteration 21: 0.149956\n",
    "Cost after iteration 22: 0.148766\n",
    "Cost after iteration 23: 0.147777\n",
    "Cost after iteration 24: 0.146955\n",
    "Cost after iteration 25: 0.146272\n",
    "Cost after iteration 26: 0.145705\n",
    "Cost after iteration 27: 0.145233\n",
    "Cost after iteration 28: 0.144841\n",
    "Cost after iteration 29: 0.144515\n",
    "Cost after iteration 30: 0.144245\n",
    "Cost after iteration 31: 0.144020\n",
    "Cost after iteration 32: 0.143833\n",
    "Cost after iteration 33: 0.143677\n",
    "Cost after iteration 34: 0.143548\n",
    "Cost after iteration 35: 0.143441\n",
    "Cost after iteration 36: 0.143352\n",
    "Cost after iteration 37: 0.143278\n",
    "Cost after iteration 38: 0.143216\n",
    "Cost after iteration 39: 0.143165\n",
    "Cost after iteration 40: 0.143123\n",
    "Cost after iteration 41: 0.143087\n",
    "Cost after iteration 42: 0.143058\n",
    "Cost after iteration 43: 0.143033\n",
    "Cost after iteration 44: 0.143013\n",
    "Cost after iteration 45: 0.142996\n",
    "Cost after iteration 46: 0.142982\n",
    "Cost after iteration 47: 0.142971\n",
    "Cost after iteration 48: 0.142961\n",
    "Cost after iteration 49: 0.142953\n",
    "Cost after iteration 50: 0.142946\n",
    "Cost after iteration 51: 0.142941\n",
    "Cost after iteration 52: 0.142936\n",
    "Cost after iteration 53: 0.142932\n",
    "Cost after iteration 54: 0.142929\n",
    "Cost after iteration 55: 0.142926\n",
    "Cost after iteration 56: 0.142924\n",
    "Cost after iteration 57: 0.142922\n",
    "Cost after iteration 58: 0.142921\n",
    "Cost after iteration 59: 0.142920\n",
    "Cost after iteration 60: 0.142919\n",
    "Cost after iteration 61: 0.142918\n",
    "Cost after iteration 62: 0.142917\n",
    "Cost after iteration 63: 0.142916\n",
    "Cost after iteration 64: 0.142916\n",
    "Cost after iteration 65: 0.142915\n",
    "Cost after iteration 66: 0.142915\n",
    "Cost after iteration 67: 0.142915\n",
    "Cost after iteration 68: 0.142915\n",
    "Cost after iteration 69: 0.142914\n",
    "Cost after iteration 70: 0.142914\n",
    "Cost after iteration 71: 0.142914\n",
    "Cost after iteration 72: 0.142914\n",
    "Cost after iteration 73: 0.142914\n",
    "Cost after iteration 74: 0.142914\n",
    "Cost after iteration 75: 0.142914\n",
    "Cost after iteration 76: 0.142914\n",
    "Cost after iteration 77: 0.142914\n",
    "Cost after iteration 78: 0.142914\n",
    "Cost after iteration 79: 0.142914\n",
    "Cost after iteration 80: 0.142914\n",
    "Cost after iteration 81: 0.142913\n",
    "Cost after iteration 82: 0.142913\n",
    "Cost after iteration 83: 0.142913\n",
    "Cost after iteration 84: 0.142913\n",
    "Cost after iteration 85: 0.142913\n",
    "Cost after iteration 86: 0.142913\n",
    "Cost after iteration 87: 0.142913\n",
    "Cost after iteration 88: 0.142913\n",
    "Cost after iteration 89: 0.142913\n",
    "Cost after iteration 90: 0.142913\n",
    "Cost after iteration 91: 0.142913\n",
    "Cost after iteration 92: 0.142913\n",
    "Cost after iteration 93: 0.142913\n",
    "Cost after iteration 94: 0.142913\n",
    "Cost after iteration 95: 0.142913\n",
    "Cost after iteration 96: 0.142913\n",
    "Cost after iteration 97: 0.142913\n",
    "Cost after iteration 98: 0.142913\n",
    "Cost after iteration 99: 0.142913\n",
    "W = [[0.36946186 0.5718172 ]]\n",
    "b = [[1.40891864e-16]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cdd2b3-8543-4422-9acb-cb33e528cf4b",
   "metadata": {},
   "source": [
    "Remember, that the initial datasets were normalized. To make the predictions, you need to normalize the original, calculate predictions with the obtained linear regression coefficients and then denormalize the result (perform the reverse process of normalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa5b22-8f69-45da-b5a2-ec467a9ccbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_multi = np.array([[1710, 7], [1200, 6], [2200, 8]]).T\n",
    "\n",
    "# Normalize using the same mean and standard deviation of the original training array X_multi.\n",
    "X_multi_mean = np.array(np.mean(X_multi)).reshape((2,1))\n",
    "X_multi_std = np.array(np.std(X_multi)).reshape((2,1))\n",
    "X_pred_multi_norm = (X_pred_multi - X_multi_mean)/ X_multi_std\n",
    "# Make predictions.\n",
    "Y_pred_multi_norm = np.matmul(W_multi, X_pred_multi_norm) + b_multi\n",
    "# Denormalize using the same mean and standard deviation of the original training array Y_multi.\n",
    "Y_pred_multi = Y_pred_multi_norm * np.std(Y_multi) + np.mean(Y_multi)\n",
    "\n",
    "print(f\"Ground living area, square feet:\\n{X_pred_multi[0]}\")\n",
    "print(f\"Rates of the overall quality of material and finish, 1-10:\\n{X_pred_multi[1]}\")\n",
    "print(f\"Predictions of sales price, $:\\n{np.round(Y_pred_multi)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
